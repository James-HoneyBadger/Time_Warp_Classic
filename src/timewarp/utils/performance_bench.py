#!/usr/bin/env python3
"""
Time_Warp Performance Benchmark - Safe Version
Comprehensive performance testing without threading issues
"""

import time
import sys
import os
import gc
import psutil
from typing import Dict, List, Any, Optional
import statistics
import tempfile

# Add project root to path
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)


class PerformanceResult:
    """Stores performance test results"""

    def __init__(
        self,
        name: str,
        execution_time: float,
        memory_delta: float,
        operations_count: int,
        success: bool,
        error: Optional[str] = None,
    ):
        self.name = name
        self.execution_time = execution_time
        self.memory_delta = memory_delta
        self.operations_count = operations_count
        self.success = success
        self.error = error
        self.ops_per_second = (
            operations_count / execution_time if execution_time > 0 else 0
        )


class TimeWarpPerformanceBench:
    """Safe performance testing for Time_Warp IDE"""

    def __init__(self):
        self.results: Dict[str, PerformanceResult] = {}
        self.process = psutil.Process()

    def get_memory_usage(self) -> float:
        """Get current memory usage in MB"""
        return self.process.memory_info().rss / 1024 / 1024

    def run_performance_test(self, name: str, test_func, operations_count: int = 1):
        """Run a performance test and record results"""
        print(f"ðŸš€ Running {name} ({operations_count:,} operations)...")

        # Pre-test cleanup
        gc.collect()
        start_memory = self.get_memory_usage()

        start_time = time.perf_counter()
        success = True
        error = None

        try:
            test_func()
        except Exception as e:
            success = False
            error = str(e)
            print(f"  âŒ Error: {error}")

        end_time = time.perf_counter()
        execution_time = end_time - start_time

        # Post-test memory check
        end_memory = self.get_memory_usage()
        memory_delta = end_memory - start_memory

        result = PerformanceResult(
            name, execution_time, memory_delta, operations_count, success, error
        )

        self.results[name] = result

        status = "âœ…" if success else "âŒ"
        print(
            f"  {status} {execution_time*1000:.2f}ms | {result.ops_per_second:,.0f} ops/sec | {memory_delta:+.2f}MB"
        )

        return result

    def test_interpreter_performance(self):
        """Test interpreter creation and basic operations"""

        def interpreter_test():
            from core.interpreter import Time_WarpInterpreter
            import tkinter as tk

            # Single threaded test
            root = tk.Tk()
            root.withdraw()

            for i in range(10):
                interpreter = Time_WarpInterpreter(root)
                # Simulate some operations
                if hasattr(interpreter, "variables"):
                    interpreter.variables[f"test_{i}"] = f"value_{i}"
                # Don't destroy interpreter in loop to avoid issues

            root.destroy()

        return self.run_performance_test(
            "Interpreter Performance", interpreter_test, 10
        )

    def test_language_execution_performance(self):
        """Test language command execution performance"""

        def language_test():
            from core.languages import PilotExecutor, BasicExecutor, LogoExecutor
            import tkinter as tk

            root = tk.Tk()
            root.withdraw()

            class MockInterpreter:
                def __init__(self):
                    self.variables = {}
                    self.output_text = None
                    self.root = root
                    self.output_buffer = []

                def add_output(self, text):
                    self.output_buffer.append(text)

            mock_interp = MockInterpreter()
            pilot = PilotExecutor(mock_interp)
            basic = BasicExecutor(mock_interp)
            logo = LogoExecutor(mock_interp)

            # Test commands
            commands = [
                (pilot, "T:Hello World"),
                (basic, "LET X = 10"),
                (logo, "FORWARD 50"),
                (pilot, "A:name"),
                (basic, "LET Y = X + 5"),
                (logo, "RIGHT 90"),
                (basic, "PRINT Y"),
                (pilot, "C:var=test"),
                (logo, "LEFT 45"),
                (basic, 'IF X > 5 THEN PRINT "Greater"'),
            ]

            for executor, cmd in commands * 100:  # 1000 total operations
                try:
                    executor.execute_command(cmd)
                except:
                    pass  # Ignore errors for performance test

            root.destroy()

        return self.run_performance_test("Language Execution", language_test, 1000)

    def test_variable_performance(self):
        """Test variable storage and retrieval performance"""

        def variable_test():
            variables = {}

            # Store 10,000 variables
            for i in range(10000):
                variables[f"VAR_{i}"] = f"Value_{i}"
                variables[f"NUM_{i}"] = i * 2
                variables[f"STR_{i}"] = f"String value {i} with extra text"

            # Retrieve and modify variables
            total = 0
            for i in range(0, 10000, 2):
                total += variables.get(f"NUM_{i}", 0)
                variables[f"VAR_{i}"] = f"Modified_{i}"

            # Batch delete
            for i in range(0, 5000):
                if f"STR_{i}" in variables:
                    del variables[f"STR_{i}"]

            return len(variables)

        return self.run_performance_test("Variable Operations", variable_test, 35000)

    def test_file_io_performance(self):
        """Test file I/O performance"""

        def file_io_test():
            temp_files = []
            temp_dir = tempfile.mkdtemp(prefix="james_perf_")

            try:
                # Create test files
                for i in range(500):
                    file_path = os.path.join(temp_dir, f"test_{i}.james")
                    content = f"""REM Test Program {i}
10 PRINT "Program {i}"
20 LET X = {i}
30 FOR J = 1 TO 10
40 PRINT J * X
50 NEXT J
60 END
"""
                    with open(file_path, "w") as f:
                        f.write(content)
                    temp_files.append(file_path)

                # Read and process files
                total_lines = 0
                for file_path in temp_files:
                    with open(file_path, "r") as f:
                        content = f.read()
                        lines = content.split("\n")
                        total_lines += len([line for line in lines if line.strip()])

                return total_lines

            finally:
                # Cleanup
                for file_path in temp_files:
                    try:
                        os.unlink(file_path)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        return self.run_performance_test("File I/O Operations", file_io_test, 1000)

    def test_memory_efficiency(self):
        """Test memory usage efficiency"""

        def memory_test():
            # Create and manipulate large data structures
            data_structures = []

            for i in range(100):
                # Large list
                large_list = list(range(1000))
                # Large dictionary
                large_dict = {f"key_{j}": f"value_{j}_extra_data" for j in range(200)}
                # String processing
                large_string = ("test " * 100) * 10

                # Process data
                filtered_list = [x for x in large_list if x % 2 == 0]
                dict_keys = list(large_dict.keys())
                string_words = large_string.split()

                # Store references temporarily
                data_structures.append(
                    {
                        "list": filtered_list,
                        "keys": dict_keys[:10],
                        "words": len(string_words),
                    }  # Keep only first 10
                )

                # Clean up large objects
                del large_list, large_dict, large_string
                del filtered_list, dict_keys, string_words

            # Final cleanup
            total_items = sum(
                len(ds["list"]) + len(ds["keys"]) + ds["words"]
                for ds in data_structures
            )
            del data_structures
            gc.collect()

            return total_items

        return self.run_performance_test("Memory Efficiency", memory_test, 100)

    def test_error_handling_performance(self):
        """Test error handling performance"""

        def error_test():
            errors_caught = 0

            # Test various error conditions
            for i in range(1000):
                try:
                    # Division by zero
                    result = i / (i % 2)
                except ZeroDivisionError:
                    errors_caught += 1

                try:
                    # Index error
                    test_list = [1, 2, 3]
                    value = test_list[i % 10]
                except IndexError:
                    errors_caught += 1

                try:
                    # Key error
                    test_dict = {"a": 1, "b": 2}
                    value = test_dict[f"key_{i}"]
                except KeyError:
                    errors_caught += 1

                try:
                    # Type error - intentionally cause type error for testing
                    if i % 7 == 0:
                        # This will cause TypeError when trying to add string and int
                        bad_value: Any = "string"
                        result = bad_value + i
                except TypeError:
                    errors_caught += 1

            return errors_caught

        return self.run_performance_test("Error Handling", error_test, 4000)

    def test_computational_performance(self):
        """Test computational performance"""

        def computation_test():
            # Math operations
            total = 0
            for i in range(10000):
                total += i**2
                total -= i * 3
                total += int(i**0.5)
                total %= 1000000

            # String operations
            text_data = []
            for i in range(1000):
                text = f"Test string {i} with additional content"
                text_data.append(text.upper().lower().replace("Test", "Sample"))

            # List operations
            numbers = list(range(5000))
            filtered = [x for x in numbers if x % 3 == 0]
            sorted_nums = sorted(filtered, reverse=True)

            return len(text_data) + len(sorted_nums) + (total % 1000)

        return self.run_performance_test(
            "Computational Performance", computation_test, 16000
        )

    def run_all_tests(self):
        """Run all performance tests"""
        print("ðŸš€ Time_Warp Performance Benchmark Suite")
        print("=" * 70)
        print(f"System: {os.name} | Python: {sys.version.split()[0]}")
        print(
            f"CPU Count: {os.cpu_count()} | Memory: {psutil.virtual_memory().total // (1024**3)} GB"
        )
        print(f"Starting Memory: {self.get_memory_usage():.2f} MB")
        print("=" * 70)

        # Run tests
        self.test_interpreter_performance()
        self.test_language_execution_performance()
        self.test_variable_performance()
        self.test_file_io_performance()
        self.test_memory_efficiency()
        self.test_error_handling_performance()
        self.test_computational_performance()

        self.print_performance_summary()

    def print_performance_summary(self):
        """Print comprehensive performance summary"""
        print("\n" + "=" * 80)
        print("ðŸ“Š PERFORMANCE BENCHMARK RESULTS")
        print("=" * 80)

        print(
            f"{'Test Name':<25} {'Time (ms)':<10} {'Ops/Sec':<12} {'Memory (MB)':<12} {'Status':<8}"
        )
        print("-" * 80)

        total_operations = 0
        total_time = 0
        successful_tests = 0

        for name, result in self.results.items():
            status = "âœ… PASS" if result.success else "âŒ FAIL"
            time_ms = result.execution_time * 1000
            ops_per_sec = (
                f"{result.ops_per_second:,.0f}" if result.ops_per_second > 0 else "N/A"
            )
            memory_str = f"{result.memory_delta:+.2f}"

            print(
                f"{result.name:<25} {time_ms:>8.2f} {ops_per_sec:>10} {memory_str:>10} {status:<8}"
            )

            if result.success:
                total_operations += result.operations_count
                total_time += result.execution_time
                successful_tests += 1

        print("\n" + "=" * 80)
        print("ðŸ“ˆ PERFORMANCE ANALYSIS")
        print("=" * 80)

        if total_time > 0:
            overall_ops_per_sec = total_operations / total_time
            print(f"Total operations: {total_operations:,}")
            print(f"Total execution time: {total_time:.3f} seconds")
            print(f"Overall throughput: {overall_ops_per_sec:,.0f} operations/second")
            print(f"Successful tests: {successful_tests}/{len(self.results)}")

        # Performance ratings
        print(f"\nðŸ† PERFORMANCE RATINGS:")
        performance_categories = [
            (0, 1000, "ðŸŒ Needs Optimization"),
            (1000, 10000, "âš ï¸  Fair Performance"),
            (10000, 50000, "âœ… Good Performance"),
            (50000, 200000, "âš¡ Very Good Performance"),
            (200000, float("inf"), "ðŸš€ Excellent Performance"),
        ]

        for name, result in sorted(
            self.results.items(), key=lambda x: x[1].ops_per_second, reverse=True
        ):
            if result.success and result.ops_per_second > 0:
                ops = result.ops_per_second
                rating = next(
                    cat[2] for cat in performance_categories if cat[0] <= ops < cat[1]
                )
                print(f"  {result.name:<25} {ops:>8,.0f} ops/sec | {rating}")

        # Memory analysis
        total_memory_usage = sum(
            r.memory_delta for r in self.results.values() if r.success
        )
        print(f"\nðŸ’¾ MEMORY ANALYSIS:")
        print(f"Total memory delta: {total_memory_usage:+.2f} MB")
        print(f"Final memory usage: {self.get_memory_usage():.2f} MB")

        if total_memory_usage < 10:
            memory_rating = "ðŸš€ Excellent memory efficiency"
        elif total_memory_usage < 50:
            memory_rating = "âœ… Good memory management"
        elif total_memory_usage < 100:
            memory_rating = "âš ï¸  Moderate memory usage"
        else:
            memory_rating = "ðŸŒ High memory usage - optimization needed"

        print(f"Memory efficiency: {memory_rating}")

        # Final recommendations
        print(f"\nðŸŽ¯ RECOMMENDATIONS:")

        failed_tests = [r for r in self.results.values() if not r.success]
        if failed_tests:
            print(f"  â€¢ Fix {len(failed_tests)} failed test(s)")
            for test in failed_tests:
                print(f"    - {test.name}: {test.error}")

        slow_tests = [
            r for r in self.results.values() if r.success and r.ops_per_second < 1000
        ]
        if slow_tests:
            print(f"  â€¢ Optimize performance for {len(slow_tests)} slow test(s)")

        high_memory_tests = [
            r for r in self.results.values() if r.success and r.memory_delta > 20
        ]
        if high_memory_tests:
            print(
                f"  â€¢ Reduce memory usage for {len(high_memory_tests)} memory-intensive test(s)"
            )

        if successful_tests == len(self.results) and total_memory_usage < 50:
            print("  â€¢ âœ… Time_Warp shows excellent overall performance")
            print("  â€¢ ðŸš€ System is optimized and ready for production use")

        print(f"\nðŸ Performance benchmark completed successfully!")


def main():
    """Run the performance benchmark"""
    try:
        benchmark = TimeWarpPerformanceBench()
        benchmark.run_all_tests()
        return 0
    except Exception as e:
        print(f"âŒ Performance benchmark failed: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
